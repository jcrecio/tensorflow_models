{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TitanicSurvivalModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhrIlVWkCzWE"
      },
      "source": [
        "%tensorflow_version 2.x # Load tensorflow 2.x into notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnPRUTNGC6ll"
      },
      "source": [
        "!pip install -q sklearn # install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQckVFcmC82M"
      },
      "source": [
        "# from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from IPython.display import clear_output\r\n",
        "from six.moves import urllib\r\n",
        "\r\n",
        "import tensorflow.compat.v2.feature_column as fc\r\n",
        "\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REqfHr4xaK-t"
      },
      "source": [
        "list(df.groupby('Title'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyn7YYbYC-kc"
      },
      "source": [
        "dftrain = pd.read_csv('https://raw.githubusercontent.com/jcrecio/ml_titanic_survival/main/train.csv') # train data frame\r\n",
        "dfeval = pd.read_csv('https://raw.githubusercontent.com/jcrecio/ml_titanic_survival/main/test.csv') # eval/test data frame\r\n",
        "df = pd.concat([dftrain, dfeval], axis=0, sort=True)\r\n",
        "\r\n",
        "df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\r\n",
        "\r\n",
        "# replacing some titles with more common ones\r\n",
        "mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\r\n",
        "           'Don': 'Mr', 'Mme': 'Mrs', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\r\n",
        "           'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\r\n",
        "df.replace({'Title': mapping}, inplace=True)\r\n",
        "\r\n",
        "df['Title'].value_counts()\r\n",
        "\r\n",
        "# impute missing Age values using median of Title groups\r\n",
        "title_ages = dict(df.groupby('Title')['Age'].median())\r\n",
        "\r\n",
        "# create a column of the average ages\r\n",
        "df['age_med'] = df['Title'].apply(lambda x: title_ages[x])\r\n",
        "\r\n",
        "# replace all missing ages with the value in this column\r\n",
        "df['Age'].fillna(df['age_med'], inplace=True, )\r\n",
        "del df['age_med']\r\n",
        "\r\n",
        "df['Embarked'].fillna(method='backfill', inplace=True) # Get rid of null values\r\n",
        "\r\n",
        "\r\n",
        "class_fares = dict(df.groupby('Pclass')['Fare'].median()) # impute missing Fare values using median of Pclass groups\r\n",
        "df['fare_med'] = df['Pclass'].apply(lambda x: class_fares[x]) # create a column of the average fares\r\n",
        "\r\n",
        "# replace all missing fares with the value in this column\r\n",
        "df['Fare'].fillna(df['fare_med'], inplace=True, )\r\n",
        "del df['fare_med']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgYrBTHATo3c"
      },
      "source": [
        "df.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace=True) # Remove variables that will not be used\r\n",
        "\r\n",
        "# Split df again in training and test datasets\r\n",
        "X_train = df[pd.notnull(df['Survived'])].drop(['Survived'], axis=1) # training data has survived not null and remove the label\r\n",
        "y_train = df[pd.notnull(df['Survived'])]['Survived'] # training data has survived not null and we only stay with the label\r\n",
        "X_test = df[pd.isnull(df['Survived'])].drop(['Survived'], axis=1) # training data has survived null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_IKdbvZPeaI"
      },
      "source": [
        "feature_columns = []\r\n",
        "\r\n",
        "for feature_name in [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\", \"Title\"]:\r\n",
        "  vocabulary = df[feature_name].unique()\r\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\r\n",
        "\r\n",
        "for feature_name in [\"Age\", \"Fare\"]:\r\n",
        "\tfeature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\r\n",
        " \r\n",
        "print(feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fqf-cKVFT2P"
      },
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\r\n",
        "  def input_function():\r\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\r\n",
        "    if shuffle:\r\n",
        "      ds = ds.shuffle(1000)\r\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\r\n",
        "    return ds\r\n",
        "  return input_function\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\r\n",
        "\r\n",
        "train_input_fn = make_input_fn(X_train, y_train, num_epochs=1, shuffle=True, batch_size=1)\r\n",
        "pred_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_val,batch_size=len(X_val),shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2hjebc2FVX8"
      },
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP78PC2WFtZ0"
      },
      "source": [
        "linear_est.train(train_input_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a6lYI-xF2O8"
      },
      "source": [
        "result = list(linear_est.predict(pred_input_fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3OlRumMXFJ1"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}